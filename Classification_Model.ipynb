{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model\n",
    "## Terms\n",
    "features = columns of variables used to predict the target<br>\n",
    "X = features (DataFrame, 1+ columns)<br>\n",
    "y = target/predicted (Series, 1 column)<br>\n",
    "X_train, y_train = X and y retailers/rows used for training<br>\n",
    "X_test, y_test = X and y retailers/rows used for testing<br>\n",
    "X_train = training predictors<br>\n",
    "\n",
    "\n",
    "## Core pipeline\n",
    "### Import data -> undersample -> rescale -> cross-validate -> evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the reshaped dataset from 'Reshaping.ipynb'\n",
    "df = pd.read_csv('Reshaped_dataset.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check variables\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptives of non-string variables\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ready = df.set_index('CustomAttribute1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split features from target for the train-test-split\n",
    "X = df_ready.drop(columns = ['anyRevenue_trial'])\n",
    "y = df_ready['anyRevenue_future']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test-split, random_state = 42 because it's the meaning of life\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescale features (min = 0, max = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store original test data as a baseline for later comparison\n",
    "baseline_test = X_test.copy()\n",
    "baseline_test['anyRevenue_future'] = y_test\n",
    "baseline_test = baseline_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# remove future variables from list of features and rescale between 0 and 1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = X_train.drop(columns = ['anyRevenue_future','Revenue_future'])\n",
    "X_train[:] = scaler.fit_transform(X_train)\n",
    "X_test = X_test.drop(columns = ['anyRevenue_future','Revenue_future'])\n",
    "X_test[:] = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning for Random Forest\n",
    "\n",
    "Calculating the best hyperparameter based only on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RSEED = 42 # To keep same randomness as before\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500, 1000],\n",
    "    'max_features': np.arange(1, 11, 1),\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Estimator for use in random search\n",
    "estimator = RandomForestClassifier(random_state = RSEED)\n",
    "\n",
    "# Create the random search model\n",
    "rfCV = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n",
    "                        scoring = 'accuracy', cv = 4, \n",
    "                        n_iter = 10, verbose = 1, random_state=RSEED)\n",
    "\n",
    "# Fit model\n",
    "rfCV.fit(X_train, y_train);\n",
    "\n",
    "clf = rfCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display feature importance\n",
    "\n",
    "Display importance of features calculated according to Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "fig=plt.figure(figsize=(12,5))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], color=\"r\")\n",
    "plt.xticks(range(X.shape[1]-1), X.columns[indices], rotation = 60, fontsize=12)\n",
    "plt.xlim([-1, int(X.shape[1])-1])\n",
    "plt.yticks(np.arange(0, (max(importances)+0.4), step = 0.1))\n",
    "plt.ylim(-0.04,0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFUSION MATRIX on test data\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap=\"Reds\", cbar = False, fmt='g')\n",
    "sns.set(font_scale=3)\n",
    "\n",
    "# passing a list is fine, no need to convert to tuples\n",
    "ax.set_xticklabels(['None','Some'])\n",
    "ax.set_yticklabels(['None','Some'])\n",
    "plt.xlabel(\"Predicted\", size = 30)\n",
    "plt.ylabel(\"Actual\", size = 30)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print precision and recall scores etc.\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform cross-validation over 4 different combinations of training data\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print scores of each cross-validation\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ROC curve\n",
    "from sklearn import preprocessing\n",
    "\n",
    "y_testBool = preprocessing.LabelEncoder().fit_transform(y_test)\n",
    "y_predBool = preprocessing.LabelEncoder().fit_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "sns.set(font_scale=1)\n",
    "logit_roc_auc = roc_auc_score(y_testBool, y_predBool)\n",
    "fpr, tpr, thresholds = roc_curve(y_testBool, clf.predict_proba(X_test)[:,1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of model impact on proportion of profitable retailers and average revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline proportion of profitable retailers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "sizesB = baseline_test.groupby('anyRevenue_future').CustomAttribute1.nunique().tolist()\n",
    "labelsB = ['Unprofitable','Profitable']\n",
    "explode = (0, 0.1)  # only \"explode\" the 2nd slice\n",
    "baseline_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(figsize=(8,7))\n",
    "ax1.pie(sizesB, explode=explode, labels=labelsB, autopct='%1.0f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion of profitable retailers after applying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filtered = baseline_test.copy()\n",
    "test_filtered['predicted'] = y_pred\n",
    "test_filtered = test_filtered[test_filtered['predicted'] == 'some']\n",
    "test_filtered.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "sizes = test_filtered.groupby('anyRevenue_future').CustomAttribute1.nunique().tolist()\n",
    "labels = ['Unprofitable','Profitable']\n",
    "explode = (0, 0.1)  # only \"explode\" the 2nd slice\n",
    "fig2, ax1 = plt.subplots(figsize=(8,7))\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.0f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot avg profitability x retailer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data:\n",
    "\n",
    "baselineRevenue = baseline_test['Revenue_future'].mean()\n",
    "modelRevenue = test_filtered['Revenue_future'].mean()\n",
    "height = [baselineRevenue,modelRevenue]\n",
    "bars = ('Baseline', 'Model')\n",
    "y_pos = np.arange(len(bars))\n",
    "\n",
    "# create plot\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1,\n",
    "                      figsize=(8,7))\n",
    "\n",
    "# Create bars\n",
    "\n",
    "plt.bar(y_pos, height, color = ['b','r'], edgecolor='black')\n",
    "\n",
    "ax.set_facecolor('white')\n",
    "ax.spines['right'].set_visible(1)\n",
    "ax.spines['top'].set_visible(1)\n",
    "\n",
    "# Create names on the x-axis\n",
    "\n",
    "plt.xticks(y_pos, bars)\n",
    "ax.tick_params(axis=\"y\", direction=\"out\", which=\"both\", right=False, left=True)\n",
    "\n",
    "plt.ylabel('£ per retailer')\n",
    "plt.yticks(np.arange(100, 1800, step=200))\n",
    "\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_color('black')\n",
    "\n",
    "# plot values\n",
    "\n",
    "for i, v in enumerate(height):\n",
    "    plt.text(y_pos[i] - 0.14 -(i*0.04), v + 50, '£'+str(int(v)))\n",
    "\n",
    "# Show graphic\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
